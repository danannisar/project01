{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import src.utils as utils\n",
    "from datetime import date, datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_init = utils.pickle_load('data/processed/train.pkl').reset_index(drop = True)\n",
    "df_test_init = utils.pickle_load('data/processed/test.pkl').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1634, 21)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_init.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate y column or dependent variable\n",
    "y_train = df_train_init.tracks_popularity.values\n",
    "y_test = df_test_init.tracks_popularity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_age(age):\n",
    "    if age <= 20:\n",
    "        cat = '<20'\n",
    "    elif 20 < age <= 30:\n",
    "        cat = '25-30'\n",
    "    elif age > 30:\n",
    "        cat = '>30'\n",
    "    else:\n",
    "        cat = 'unknown'\n",
    "\n",
    "    return cat\n",
    "\n",
    "def cat_days_after_debut(days):\n",
    "    if days <= 365:\n",
    "        cat = '<1year'\n",
    "    elif 365 < days <= 365 * 5:\n",
    "        cat = '1-5years'\n",
    "    elif 365 * 5 < days <= 365 * 10:\n",
    "        cat = '5-10years'\n",
    "    elif days > 365 * 10:\n",
    "        cat = '>10years'\n",
    "    else:\n",
    "        cat = 'unknown'\n",
    "        \n",
    "    return cat\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelencoder(train, test, feature):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[feature])\n",
    "    train[feature] = le.transform(train[feature])\n",
    "    test[feature] = le.transform(test[feature])\n",
    "\n",
    "    return train[feature], test[feature]\n",
    "\n",
    "def onehotencoder(train, test, feature):\n",
    "    \n",
    "    ohe = OneHotEncoder()\n",
    "    ohe.fit(train[[feature]])\n",
    "    train_encoded = pd.DataFrame(ohe.transform(train[[feature]]).toarray())\n",
    "    train_encoded.columns = ohe.get_feature_names([feature])\n",
    "\n",
    "    test_encoded = pd.DataFrame(ohe.transform(test[[feature]]).toarray())\n",
    "    test_encoded.columns = ohe.get_feature_names([feature])\n",
    "\n",
    "    return train_encoded, test_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing():\n",
    "\n",
    "    # Mengganti kolom days_after_debut dan mean_age menjadi kolom kategorikal\n",
    "    df['cat_age'] = df.apply(lambda row: cat_age(row['mean_age']), axis=1)\n",
    "    df['cat_days_debut'] = df.apply(lambda row: cat_age(row['days_after_debut']), axis=1)\n",
    "\n",
    "    # Drop kolom explicit dan time_signature karena dari EDA dianggap tidak berpengaruh\n",
    "    df.drop(['mean_age', 'days_after_debut', 'explicit', 'time_signature', 'members', 'tracks_popularity'],axis = 1, inplace=True)\n",
    "\n",
    "    # creating instance of labelencoder\n",
    "    labelencoder = LabelEncoder()\n",
    "    labelencoder.fit(['A#', 'C#', 'B', 'C', 'G', 'F', 'D', 'A', 'G#', 'E', 'F#', 'D#'])\n",
    "\n",
    "    # Assigning numerical values and storing in another column\n",
    "    df['key'] = labelencoder.transform(df['key'])\n",
    "\n",
    "    onehotencoder = OneHotEncoder(sparse=False)\n",
    "    modality_encoded = pd.DataFrame (onehotencoder.fit_transform(df[['modality']]))\n",
    "    modality_encoded.columns = onehotencoder.get_feature_names(['modality'])\n",
    "\n",
    "    company_encoded = pd.DataFrame (onehotencoder.fit_transform(df[['big5_company']]))\n",
    "    company_encoded.columns = onehotencoder.get_feature_names(['big5_company'])\n",
    "\n",
    "    age_encoded = pd.DataFrame (onehotencoder.fit_transform(df[['cat_age']]))\n",
    "    age_encoded.columns = onehotencoder.get_feature_names(['cat_age'])\n",
    "\n",
    "    debutdays_encoded = pd.DataFrame (onehotencoder.fit_transform(df[['cat_days_debut']]))\n",
    "    debutdays_encoded.columns = onehotencoder.get_feature_names(['cat_days_debut'])\n",
    "\n",
    "    df.drop(['modality', 'big5_company', 'cat_age', 'cat_days_debut'], axis = 1, inplace=True)\n",
    "    df_concat = pd.concat([df, modality_encoded, company_encoded, age_encoded, debutdays_encoded], axis = 1)\n",
    "\n",
    "    return df_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train \u001b[39m=\u001b[39m preprocessing(df_train_init)\n\u001b[1;32m      2\u001b[0m \u001b[39m#X_test = preprocessing(df_test_init)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[213], line 15\u001b[0m, in \u001b[0;36mpreprocessing\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     12\u001b[0m labelencoder\u001b[39m.\u001b[39mfit([\u001b[39m'\u001b[39m\u001b[39mA#\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC#\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mB\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mG\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mD\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mG#\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mE\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mF#\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mD#\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m \u001b[39m# Assigning numerical values and storing in another column\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mkey\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m labelencoder\u001b[39m.\u001b[39;49mtransform(df[\u001b[39m'\u001b[39;49m\u001b[39mkey\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     17\u001b[0m onehotencoder\u001b[39m=\u001b[39mOneHotEncoder(sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m modality_encoded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame (onehotencoder\u001b[39m.\u001b[39mfit_transform(df[[\u001b[39m'\u001b[39m\u001b[39mmodality\u001b[39m\u001b[39m'\u001b[39m]]))\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:138\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mif\u001b[39;00m _num_samples(y) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    136\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([])\n\u001b[0;32m--> 138\u001b[0m \u001b[39mreturn\u001b[39;00m _encode(y, uniques\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses_)\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/utils/_encode.py:229\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[39mif\u001b[39;00m check_unknown:\n\u001b[0;32m--> 229\u001b[0m         diff \u001b[39m=\u001b[39m _check_unknown(values, uniques)\n\u001b[1;32m    230\u001b[0m         \u001b[39mif\u001b[39;00m diff:\n\u001b[1;32m    231\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my contains previously unseen labels: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(diff)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/utils/_encode.py:303\u001b[0m, in \u001b[0;36m_check_unknown\u001b[0;34m(values, known_values, return_mask)\u001b[0m\n\u001b[1;32m    300\u001b[0m         valid_mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(\u001b[39mlen\u001b[39m(values), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    302\u001b[0m \u001b[39m# check for nans in the known_values\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39;49misnan(known_values)\u001b[39m.\u001b[39many():\n\u001b[1;32m    304\u001b[0m     diff_is_nan \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39misnan(diff)\n\u001b[1;32m    305\u001b[0m     \u001b[39mif\u001b[39;00m diff_is_nan\u001b[39m.\u001b[39many():\n\u001b[1;32m    306\u001b[0m         \u001b[39m# removes nan from valid_mask\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "X_train = preprocessing(df_train_init)\n",
    "#X_test = preprocessing(df_test_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_init.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.15055079559364\n",
      "247.1878607737356\n"
     ]
    }
   ],
   "source": [
    "# baseline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "baseline_pred = np.mean(y_train)\n",
    "print(baseline_pred)\n",
    "baseline_mse = mean_squared_error(y_train, \n",
    "                                  np.ones(len(y_train)) * baseline_pred)\n",
    "print(baseline_mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, y_train,\n",
    "              X_test, y_test):\n",
    "    # 1. Buat objek\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    # 2. Lakukan cross-val\n",
    "    scores = cross_val_score(estimator = lr,\n",
    "                             X = X_train,\n",
    "                             y = y_train,\n",
    "                             cv = 5,\n",
    "                             scoring = \"neg_mean_squared_error\")\n",
    "    \n",
    "    cv_score = - np.mean(scores)\n",
    "    \n",
    "    # 3. Fit model\n",
    "    lr.fit(X = X_train,\n",
    "           y = y_train)\n",
    "    \n",
    "    # 4. Cari train score\n",
    "    y_train_pred = lr.predict(X_train)\n",
    "    train_score = mean_squared_error(y_train, y_train_pred)\n",
    "    \n",
    "    # 4. Cari test score\n",
    "    y_test_pred = lr.predict(X_test)\n",
    "    test_score = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "    # 5. Ekstrak coefficient\n",
    "    coef_ = lr.coef_\n",
    "    intercept_ = lr.intercept_\n",
    "    lr_params = np.append(coef_, intercept_)\n",
    "\n",
    "    lr_params_df = pd.DataFrame(lr_params,\n",
    "                                index = list(X_train.columns) + [\"constant\"],\n",
    "                                columns = [\"coefficient\"])\n",
    "    \n",
    "    return lr, train_score, cv_score, test_score, lr_params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 25 features, but LinearRegression is expecting 26 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lr, train_score, cv_score, test_score, lr_params_df \u001b[39m=\u001b[39m fit_model(X_train \u001b[39m=\u001b[39;49m X_train,\n\u001b[1;32m      2\u001b[0m                                                                 y_train \u001b[39m=\u001b[39;49m y_train,\n\u001b[1;32m      3\u001b[0m                                                                 X_test \u001b[39m=\u001b[39;49m X_test,\n\u001b[1;32m      4\u001b[0m                                                                 y_test \u001b[39m=\u001b[39;49m y_test)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain score: \u001b[39m\u001b[39m{\u001b[39;00mtrain_score\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, cv score: \u001b[39m\u001b[39m{\u001b[39;00mcv_score\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, test_score: \u001b[39m\u001b[39m{\u001b[39;00mtest_score\u001b[39m:\u001b[39;00m\u001b[39m.3f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[185], line 24\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     21\u001b[0m train_score \u001b[39m=\u001b[39m mean_squared_error(y_train, y_train_pred)\n\u001b[1;32m     23\u001b[0m \u001b[39m# 4. Cari test score\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m y_test_pred \u001b[39m=\u001b[39m lr\u001b[39m.\u001b[39;49mpredict(X_test)\n\u001b[1;32m     25\u001b[0m test_score \u001b[39m=\u001b[39m mean_squared_error(y_test, y_test_pred)\n\u001b[1;32m     27\u001b[0m \u001b[39m# 5. Ekstrak coefficient\u001b[39;00m\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/linear_model/_base.py:386\u001b[0m, in \u001b[0;36mLinearModel.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    373\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[39m    Predict using the linear model.\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m        Returns predicted values.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_decision_function(X)\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/linear_model/_base.py:369\u001b[0m, in \u001b[0;36mLinearModel._decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_decision_function\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[1;32m    367\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m--> 369\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcoo\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    370\u001b[0m     \u001b[39mreturn\u001b[39;00m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m--> 600\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[1;32m    602\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/home/dana/ai-ml-pacmann/project01/lib/python3.9/site-packages/sklearn/base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 400\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 25 features, but LinearRegression is expecting 26 features as input."
     ]
    }
   ],
   "source": [
    "lr, train_score, cv_score, test_score, lr_params_df = fit_model(X_train = X_train,\n",
    "                                                                y_train = y_train,\n",
    "                                                                X_test = X_test,\n",
    "                                                                y_test = y_test)\n",
    "print(f\"train score: {train_score:.3f}, cv score: {cv_score:.3f}, test_score: {test_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
